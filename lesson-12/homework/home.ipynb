{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc=\"\"\" \n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Weather Forecast</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h4>5-Day Weather Forecast</h4>\n",
    "    <table>\n",
    "        <thead>\n",
    "            <tr>\n",
    "                <th>Day</th>\n",
    "                <th>Temperature</th>\n",
    "                <th>Condition</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr>\n",
    "                <td>Monday</td>\n",
    "                <td>25°C</td>\n",
    "                <td>Sunny</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Tuesday</td>\n",
    "                <td>22°C</td>\n",
    "                <td>Cloudy</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Wednesday</td>\n",
    "                <td>18°C</td>\n",
    "                <td>Rainy</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Thursday</td>\n",
    "                <td>20°C</td>\n",
    "                <td>Partly Cloudy</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Friday</td>\n",
    "                <td>30°C</td>\n",
    "                <td>Sunny</td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Weather Forecast\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h4>\n",
      "   5-Day Weather Forecast\n",
      "  </h4>\n",
      "  <table>\n",
      "   <thead>\n",
      "    <tr>\n",
      "     <th>\n",
      "      Day\n",
      "     </th>\n",
      "     <th>\n",
      "      Temperature\n",
      "     </th>\n",
      "     <th>\n",
      "      Condition\n",
      "     </th>\n",
      "    </tr>\n",
      "   </thead>\n",
      "   <tbody>\n",
      "    <tr>\n",
      "     <td>\n",
      "      Monday\n",
      "     </td>\n",
      "     <td>\n",
      "      25°C\n",
      "     </td>\n",
      "     <td>\n",
      "      Sunny\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      Tuesday\n",
      "     </td>\n",
      "     <td>\n",
      "      22°C\n",
      "     </td>\n",
      "     <td>\n",
      "      Cloudy\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      Wednesday\n",
      "     </td>\n",
      "     <td>\n",
      "      18°C\n",
      "     </td>\n",
      "     <td>\n",
      "      Rainy\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      Thursday\n",
      "     </td>\n",
      "     <td>\n",
      "      20°C\n",
      "     </td>\n",
      "     <td>\n",
      "      Partly Cloudy\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      Friday\n",
      "     </td>\n",
      "     <td>\n",
      "      30°C\n",
      "     </td>\n",
      "     <td>\n",
      "      Sunny\n",
      "     </td>\n",
      "    </tr>\n",
      "   </tbody>\n",
      "  </table>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday: 25°C, Sunny\n",
      "Tuesday: 22°C, Cloudy\n",
      "Wednesday: 18°C, Rainy\n",
      "Thursday: 20°C, Partly Cloudy\n",
      "Friday: 30°C, Sunny\n"
     ]
    }
   ],
   "source": [
    "forecasts = []\n",
    "table = soup.find(\"table\") \n",
    "rows = table.find(\"tbody\").find_all(\"tr\")  \n",
    "for row in rows:\n",
    "    columns = row.find_all(\"td\")  \n",
    "    if len(columns) == 3: \n",
    "        day = columns[0].text.strip()\n",
    "        temp = columns[1].text.strip()\n",
    "        condition = columns[2].text.strip()\n",
    "        \n",
    "        forecasts.append({\n",
    "            \"Day\": day,\n",
    "            \"Temperature\": temp,\n",
    "            \"Condition\": condition\n",
    "        })\n",
    "\n",
    "\n",
    "for forecast in forecasts:\n",
    "    print(f\"{forecast['Day']}: {forecast['Temperature']}, {forecast['Condition']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday: 25°C, Sunny\n",
      "Friday: 30°C, Sunny\n",
      "Hottest day(s):\n",
      "Friday: 30°C°C, Sunny\n",
      "No forecast data available.\n"
     ]
    }
   ],
   "source": [
    "sunnydays=[forecast for forecast in forecasts if forecast['Condition']=='Sunny']\n",
    "for day in sunnydays:\n",
    "    print(f\"{day['Day']}: {day['Temperature']}, {day['Condition']}\")\n",
    "\n",
    "hottest=max(forecast['Temperature'] for forecast in forecasts)\n",
    "hottest_days=[forecast for forecast in forecasts if forecast['Temperature']==hottest]\n",
    "print(\"Hottest day(s):\")\n",
    "for day in hottest_days:\n",
    "        print(f\"{day['Day']}: {day['Temperature']}°C, {day['Condition']}\")\n",
    "else:\n",
    "    print(\"No forecast data available.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "url='https://realpython.github.io/fake-jobs'\n",
    "response=requests.get(url)\n",
    "def scrape_jobs():\n",
    "    \"\"\"Scrape job listings from the website with error handling\"\"\"\n",
    "    base_url = 'https://realpython.github.io/fake-jobs/'\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    jobs = []\n",
    "    job_cards = soup.find_all('div', class_='card')\n",
    "    \n",
    "    for card in job_cards:\n",
    "        try:\n",
    "            title_elem = card.find('h2', class_='title')\n",
    "            title = title_elem.text.strip() if title_elem else \"N/A\"\n",
    "            \n",
    "            \n",
    "            company_elem = card.find('h3', class_='company')\n",
    "            company = company_elem.text.strip() if company_elem else \"N/A\"\n",
    "            \n",
    "            \n",
    "            location_elem = card.find('p', class_='location')\n",
    "            location = location_elem.text.strip() if location_elem else \"N/A\"\n",
    "    \n",
    "            description_elem = card.find('p', class_='description')\n",
    "            if not description_elem:\n",
    "                description_elem = card.find('div', class_='content')\n",
    "            description = description_elem.text.strip() if description_elem else \"N/A\"\n",
    "            \n",
    "            footer_links = card.find_all('a', class_='card-footer-item')\n",
    "            apply_link = urljoin(base_url, footer_links[1]['href']) if len(footer_links) > 1 else \"N/A\"\n",
    "            \n",
    "            jobs.append({\n",
    "                'title': title,\n",
    "                'company': company,\n",
    "                'location': location,\n",
    "                'description': description,\n",
    "                'apply_link': apply_link\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing a job card: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from time import sleep\n",
    "\n",
    "def scrape_demoblaze_laptops():\n",
    "    base_url = \"https://www.demoblaze.com\"\n",
    "    laptops_data = []\n",
    "    \n",
    "    # Start with the laptops page\n",
    "    current_page = f\"{base_url}/#\"\n",
    "    page_num = 1\n",
    "    \n",
    "    while True:\n",
    "        print(f\"Scraping page {page_num}...\")\n",
    "        \n",
    "        # Get the page content (using requests with headers to mimic a browser)\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(current_page, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all laptop cards\n",
    "        laptop_cards = soup.find_all('div', class_='card')\n",
    "        \n",
    "        if not laptop_cards:\n",
    "            print(\"No more laptops found.\")\n",
    "            break\n",
    "        \n",
    "        for card in laptop_cards:\n",
    "            try:\n",
    "               \n",
    "                name = card.find('h4', class_='card-title').text.strip()\n",
    "                \n",
    "               \n",
    "                price = card.find('h5').text.strip()\n",
    "                \n",
    "                description = card.find('p', class_='card-text').text.strip()\n",
    "                \n",
    "                laptops_data.append({\n",
    "                    \"name\": name,\n",
    "                    \"price\": price,\n",
    "                    \"description\": description\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing a laptop card: {e}\")\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        next_button = soup.find('button', id='next2')\n",
    "        if not next_button or 'disabled' in next_button.get('class', []):\n",
    "            print(\"Reached the last page.\")\n",
    "            break\n",
    "        \n",
    "\n",
    "        page_num += 1\n",
    "        current_page = f\"{base_url}/#\"\n",
    "        sleep(2)  \n",
    "    \n",
    "    return laptops_data\n",
    "\n",
    "def save_to_json(data, filename='laptops_data.json'):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    laptops = scrape_demoblaze_laptops()\n",
    "    save_to_json(laptops)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
